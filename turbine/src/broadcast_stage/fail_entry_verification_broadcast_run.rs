use {
    super::*,
    crate::cluster_nodes::ClusterNodesCache,
    trezoa_entry::block_component::BlockComponent,
    trezoa_hash::Hash,
    trezoa_keypair::Keypair,
    trezoa_ledger::shred::{ProcessShredsStats, ReedSolomonCache, Shredder},
    trezoa_votor::event::VotorEventSender,
    std::{thread::sleep, time::Duration},
    tokio::sync::mpsc::Sender as AsyncSender,
};

pub const NUM_BAD_SLOTS: u64 = 10;
pub const SLOT_TO_RESOLVE: u64 = 32;

#[derive(Clone)]
pub(super) struct FailEntryVerificationBroadcastRun {
    shred_version: u16,
    good_shreds: Vec<Shred>,
    current_slot: Slot,
    chained_merkle_root: Hash,
    carryover_entry: Option<WorkingBankEntryMarker>,
    next_shred_index: u32,
    next_code_index: u32,
    cluster_nodes_cache: Arc<ClusterNodesCache<BroadcastStage>>,
    reed_solomon_cache: Arc<ReedSolomonCache>,
    migration_status: Arc<MigrationStatus>,
}

impl FailEntryVerificationBroadcastRun {
    pub(super) fn new(shred_version: u16, migration_status: Arc<MigrationStatus>) -> Self {
        let cluster_nodes_cache = Arc::new(ClusterNodesCache::<BroadcastStage>::new(
            CLUSTER_NODES_CACHE_NUM_EPOCH_CAP,
            CLUSTER_NODES_CACHE_TTL,
        ));
        Self {
            shred_version,
            good_shreds: vec![],
            current_slot: 0,
            chained_merkle_root: Hash::default(),
            carryover_entry: None,
            next_shred_index: 0,
            next_code_index: 0,
            cluster_nodes_cache,
            reed_solomon_cache: Arc::<ReedSolomonCache>::default(),
            migration_status,
        }
    }
}

impl BroadcastRun for FailEntryVerificationBroadcastRun {
    fn run(
        &mut self,
        keypair: &Keypair,
        blockstore: &Blockstore,
        receiver: &Receiver<WorkingBankEntryMarker>,
        socket_sender: &Sender<(Arc<Vec<Shred>>, Option<BroadcastShredBatchInfo>)>,
        blockstore_sender: &Sender<(Arc<Vec<Shred>>, Option<BroadcastShredBatchInfo>)>,
        _votor_event_sender: &VotorEventSender,
    ) -> Result<()> {
        // 1) Pull entries from banking stage
        let mut stats = ProcessShredsStats::default();
        let receive_results =
            broadcast_utils::recv_slot_entries(receiver, &mut self.carryover_entry, &mut stats)?;
        let bank = receive_results.bank.clone();
        let last_tick_height = receive_results.last_tick_height;

        let send_header = if bank.slot() != self.current_slot {
            self.chained_merkle_root = broadcast_utils::get_chained_merkle_root_from_parent(
                bank.slot(),
                bank.parent_slot(),
                blockstore,
            )
            .unwrap();
            self.next_shred_index = 0;
            self.next_code_index = 0;
            self.current_slot = bank.slot();

            self.migration_status.is_alpenglow_enabled()
        } else {
            false
        };

        // 2) If we're past SLOT_TO_RESOLVE, insert the correct shreds so validators can repair
        // and make progress
        if bank.slot() > SLOT_TO_RESOLVE && !self.good_shreds.is_empty() {
            info!("Resolving bad shreds");
            let shreds = std::mem::take(&mut self.good_shreds);
            blockstore_sender.send((Arc::new(shreds), None))?;
        }

        // 3) Convert entries to shreds + generate coding shreds. Set a garbage PoH on the last entry
        // in the slot to make verification fail on validators
        let (component, last_entries) = {
            if last_tick_height == bank.max_tick_height() && bank.slot() < NUM_BAD_SLOTS {
                // Corrupt the final entry in the component
                let (good_last_entry, bad_last_entry, component) =
                    if let BlockComponent::EntryBatch(mut entries) = receive_results.component {
                        let last_entry = entries.last_mut().expect("Expected at least one entry");
                        let good = last_entry.clone();
                        last_entry.hash = Hash::default();
                        let bad = last_entry.clone();
                        (good, bad, BlockComponent::EntryBatch(entries))
                    } else {
                        panic!("Expected EntryBatch component");
                    };

                (component, Some((good_last_entry, bad_last_entry)))
            } else {
                (receive_results.component, None)
            }
        };

        let shredder = Shredder::new(
            bank.slot(),
            bank.parent().unwrap().slot(),
            (bank.tick_height() % bank.ticks_per_slot()) as u8,
            self.shred_version,
        )
        .expect("Expected to create a new shredder");

        let (header_data_shreds, header_coding_shreds) = if send_header {
            let header = produce_block_header(bank.parent_slot(), self.chained_merkle_root);

            shredder.component_to_merkle_shreds_for_tests(
                keypair,
                &BlockComponent::BlockMarker(header),
                false,
                Some(self.chained_merkle_root),
                self.next_shred_index,
                self.next_code_index,
                &self.reed_solomon_cache,
                &mut stats,
            )
        } else {
            (vec![], vec![])
        };
        if let Some(shred) = header_data_shreds.iter().max_by_key(|shred| shred.index()) {
            self.chained_merkle_root = shred.merkle_root().unwrap();
        }
        self.next_shred_index += header_data_shreds.len() as u32;
        if let Some(index) = header_coding_shreds.iter().map(Shred::index).max() {
            self.next_code_index = index + 1;
        }

        let (component_data_shreds, component_coding_shreds) = shredder
            .component_to_merkle_shreds_for_tests(
                keypair,
                &component,
                last_tick_height == bank.max_tick_height() && last_entries.is_none(),
                Some(self.chained_merkle_root),
                self.next_shred_index,
                self.next_code_index,
                &self.reed_solomon_cache,
                &mut stats,
            );
        if let Some(shred) = component_data_shreds
            .iter()
            .max_by_key(|shred| shred.index())
        {
            self.chained_merkle_root = shred.merkle_root().unwrap();
        }
        self.next_shred_index += component_data_shreds.len() as u32;
        if let Some(index) = component_coding_shreds.iter().map(Shred::index).max() {
            self.next_code_index = index + 1;
        }

        // Chain header shreds with component shreds
        let data_shreds = header_data_shreds
            .into_iter()
            .chain(component_data_shreds)
            .collect::<Vec<_>>();
        let last_shreds = last_entries.map(|(good_last_entry, bad_last_entry)| {
            let (good_last_data_shred, _) = shredder.entries_to_merkle_shreds_for_tests(
                keypair,
                &[good_last_entry],
                true,
                Some(self.chained_merkle_root),
                self.next_shred_index,
                self.next_code_index,
                &self.reed_solomon_cache,
                &mut stats,
            );
            // Don't mark the last shred as last so that validators won't know
            // that they've gotten all the shreds, and will continue trying to
            // repair.
            let (bad_last_data_shred, _) = shredder.entries_to_merkle_shreds_for_tests(
                keypair,
                &[bad_last_entry],
                false,
                Some(self.chained_merkle_root),
                self.next_shred_index,
                self.next_code_index,
                &self.reed_solomon_cache,
                &mut stats,
            );
            assert_eq!(good_last_data_shred.len(), 1);
            self.chained_merkle_root = good_last_data_shred.last().unwrap().merkle_root().unwrap();
            self.next_shred_index += 1;
            (good_last_data_shred, bad_last_data_shred)
        });

        let data_shreds = Arc::new(data_shreds);
        blockstore_sender.send((data_shreds.clone(), None))?;
        // 4) Start broadcast step
        socket_sender.send((data_shreds, None))?;
        if let Some((good_last_data_shred, bad_last_data_shred)) = last_shreds {
            // Stash away the good shred so we can rewrite them later
            self.good_shreds.extend(good_last_data_shred.clone());
            let good_last_data_shred = Arc::new(good_last_data_shred);
            let bad_last_data_shred = Arc::new(bad_last_data_shred);
            // Store the good shred so that blockstore will signal ClusterSlots
            // that the slot is complete
            blockstore_sender.send((good_last_data_shred, None))?;
            loop {
                // Wait for slot to be complete
                if blockstore.is_full(bank.slot()) {
                    break;
                }
                sleep(Duration::from_millis(10));
            }
            // Store the bad shred so we serve bad repairs to validators catching up
            blockstore_sender.send((bad_last_data_shred.clone(), None))?;
            // Send bad shreds to rest of network
            socket_sender.send((bad_last_data_shred, None))?;
        }
        Ok(())
    }
    fn transmit(
        &mut self,
        receiver: &TransmitReceiver,
        cluster_info: &ClusterInfo,
        sock: BroadcastSocket,
        bank_forks: &RwLock<BankForks>,
        quic_endpoint_sender: &AsyncSender<(SocketAddr, Bytes)>,
    ) -> Result<()> {
        let (shreds, _) = receiver.recv()?;
        broadcast_shreds(
            sock,
            &shreds,
            &self.cluster_nodes_cache,
            &AtomicInterval::default(),
            &mut TransmitShredsStats::default(),
            cluster_info,
            bank_forks,
            cluster_info.socket_addr_space(),
            quic_endpoint_sender,
        )
    }
    fn record(&mut self, receiver: &RecordReceiver, blockstore: &Blockstore) -> Result<()> {
        let (all_shreds, _) = receiver.recv()?;
        blockstore
            .insert_shreds(all_shreds.to_vec(), None, true)
            .expect("Failed to insert shreds in blockstore");
        Ok(())
    }
}
